{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pymongo  \n",
    "from pymongo import MongoClient\n",
    "import pyodbc\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "headers = {\n",
    "    'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"\n",
    "}  \n",
    "\n",
    "# next_url='/knowledge/knowledge_lp.aspx?ArticleType=A&CategoryId=A&PageNumber=184&PageSize=10&dateS=&dateE='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_url='https://www.themoviedb.org/movie/19995-avatar/discuss?language=en'\n",
    "all_html=requests.get(target_url,headers = headers)    \n",
    "soup1=BeautifulSoup(all_html.text,'lxml')\n",
    "\n",
    "#抓genreral版的文章\n",
    "article_general=soup1.find('h3',class_='breadcrumbs')\n",
    "Discussion_board=article_general.text\n",
    "for url in article_general:\n",
    "    #拿到gerneral討論版的url\n",
    "    general=url\n",
    "\n",
    "target_url='https://www.themoviedb.org'+general['href']\n",
    "disscuss_html=requests.get(target_url,headers = headers)    \n",
    "soup1=BeautifulSoup(disscuss_html.text,'lxml')\n",
    "\n",
    "disscuss_list=soup1.find_all('a',class_='topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num=0\n",
    "for each_a in disscuss_list:\n",
    "    craw_reply(each_a['href'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def craw_reply(href):\n",
    "    \n",
    "    time.sleep(1)\n",
    "    global num\n",
    "    global Discussion_board\n",
    "    num=num+1\n",
    "    target_url='https://www.themoviedb.org'+href\n",
    "    try:\n",
    "        all_html=requests.get(target_url,headers = headers)    \n",
    "        soup1=BeautifulSoup(all_html.text,'lxml')\n",
    "\n",
    "        Question_title=soup1.find('h2',class_='no_capitalize bigger_image').text\n",
    "        reply_list=soup1.find_all('div',class_='content convert_emoji')\n",
    "        artContent=''\n",
    "        for rep in reply_list:\n",
    "\n",
    "\n",
    "            rep_href= rep.find_all('a')\n",
    "            for j in  rep_href:\n",
    "                rep.a.extract()#delete all href in reply\n",
    "\n",
    "            artContent=artContent+rep.text\n",
    "\n",
    "        Date_info=soup1.find('h3',class_='by')\n",
    "        po_href=Date_info\n",
    "        po_href.a.extract()\n",
    "        Date_info=Date_info.text\n",
    "        artDate=Date_info[Date_info.index('on'):len(Date_info)]   \n",
    "        artDate=datetime.strptime(artDate.strip(), 'on %B %d, %Y at   %I:%M%p').strftime('%Y/%m/%d ')\n",
    "        artTitle=Question_title\n",
    "\n",
    "        bag={\n",
    "            'nId':num,\n",
    "            'Disscussion_board':Discussion_board,\n",
    "            'artTitle':artTitle,\n",
    "            'artUrl':target_url,\n",
    "\n",
    "            'artContent':artContent,\n",
    "            'artDate':artDate,\n",
    "            'error':0\n",
    "        }\n",
    "\n",
    "        #抓取成功\n",
    "        print(str(num)+\".:\"+artTitle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "\n",
    "        bag={\n",
    "            'nId':num,\n",
    "            'artTitle':\"\",\n",
    "            'artUrl':target_url,\n",
    "\n",
    "            'artContent':\"\",\n",
    "            \n",
    "            'artDate':\"\",\n",
    "            'error':1\n",
    "        }\n",
    "        #抓取失敗\n",
    "        print(e)\n",
    "        print(str(num)+\".:Error find!Connect again...\")\n",
    "        time.sleep(20)\n",
    "\n",
    "    finally:\n",
    "        ###連接MONGO\n",
    "\n",
    "\n",
    "        uri = \"\"\n",
    "        client = MongoClient(uri)\n",
    "\n",
    "        db = client.BI_Project\n",
    "        one_document = db.movie_craw\n",
    "\n",
    "\n",
    "        current_insert=one_document.find({'artUrl':target_url}).count()\n",
    "        if(current_insert==0):one_document.insert_one(bag)\n",
    "        if(current_insert>0):\n",
    "            print(\"已存在此文章\")\n",
    "            num=num-1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###連接MONGO\n",
    "\n",
    "\n",
    "uri = \"\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "db = client.BI_Project\n",
    "one_document = db.movie_craw\n",
    "\n",
    "\n",
    "one_document.insert_one({'i':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=craw_reply('/movie/19995-avatar/discuss/58a0078cc3a36802fd002711')\n",
    "print(a)\n",
    "datetime.strptime('on August 22, 2017 at 12:10AM', 'on %B %d, %Y at   %I:%M%p').strftime('%Y/%m/%d ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f = open('./mongo_to_csv/agri_craw2.csv', 'r',encoding='utf-8-sig')\n",
    "for row in csv.DictReader(f):\n",
    "    list.append(len(row['artContent']) )\n",
    "f.close()\n",
    "print(max(list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
