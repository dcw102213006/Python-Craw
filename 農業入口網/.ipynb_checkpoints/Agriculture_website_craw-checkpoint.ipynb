{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pymongo  \n",
    "from pymongo import MongoClient\n",
    "import pyodbc\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"\n",
    "}  \n",
    "\n",
    "# next_url='/knowledge/knowledge_lp.aspx?ArticleType=A&CategoryId=A&PageNumber=184&PageSize=10&dateS=&dateE='\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_url='http://kmweb.coa.gov.tw/knowledge/knowledge_cp.aspx?ArticleId=1524691&ArticleType=A&CategoryId=&kpi=0&dateS=&dateE='\n",
    "all_html=requests.get(target_url,headers = headers)    \n",
    "soup1=BeautifulSoup(all_html.text,'lxml')\n",
    "title=soup1.find('span',id='ctl00_ContentPlaceHolder1_QuestionText').h3.text\n",
    "title=re.sub(\"標題：\",\"\",str(title))\n",
    "contect=soup1.find('div',class_='problem').text\n",
    "article_infor=soup1.find(class_='subright').find_all('li')\n",
    "\n",
    "reply_list=soup1.find_all(class_='DisList')\n",
    "# print(reply_infor[0].find_all('li')[0].text)\n",
    "# print(reply_infor[0].find_all('li')[0].nextSibling)\n",
    "\n",
    "# print(reply_infor[0].find_all('li')[1].text)\n",
    "reply=[]\n",
    "\n",
    "#for each replier\n",
    "for i in reply_list:\n",
    "    \n",
    "    rep_content=i.find('p')#get reply content\n",
    "    rep_href= rep_content.find_all('a')\n",
    "    for j in  rep_href:\n",
    "        rep_content.a.extract()#delete all href in reply\n",
    "    \n",
    "    replier_info=i.find_all('li')\n",
    "    \n",
    "    rep_name=replier_info[0].text\n",
    "    rep_date=replier_info[1].text\n",
    "    rep_date=re.sub(\"發表於 \",\"\",str(rep_date))\n",
    "    rep_member=replier_info[0].nextSibling\n",
    "    rep_member=re.sub(\"\\(\",\"\",str(rep_member))\n",
    "    rep_member=re.sub(\"\\)\",\"\",str(rep_member))\n",
    "    reply.append({\n",
    "        'rep_content':rep_content.text,\n",
    "        'rep_name':rep_name,\n",
    "        'rep_member':rep_member,\n",
    "        'rep_date':rep_date\n",
    "        \n",
    "    })\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_url=\"/knowledge/knowledge_lp.aspx?ArticleType=&CategoryId=A\"\n",
    "num=0\n",
    "last_art=False\n",
    "\n",
    "while(not last_art):\n",
    "    try:\n",
    "        print(\"當前頁面:http://kmweb.coa.gov.tw\"+next_url)\n",
    "        target_url='http://kmweb.coa.gov.tw'+next_url\n",
    "        all_html=requests.get(target_url,headers = headers)    \n",
    "        soup1=BeautifulSoup(all_html.text,'lxml')\n",
    "        list=soup1.find_all(class_='DisList')\n",
    "        list=soup1.find(class_='lp').find_all('tr')\n",
    "\n",
    "        #目前位置：首頁>農>最新發問>列表10篇文章\n",
    "        for i in list:\n",
    "            if(i.a is not None):\n",
    "                num=num+1\n",
    "                \n",
    "                craw_(i.a['href'])\n",
    "        \n",
    "        next_ten=soup1.find(id='ctl00_ContentPlaceHolder1_NextLink')#抓取新的10筆\n",
    "        next_url=next_ten['href']\n",
    "        print(\"下一頁\")\n",
    "\n",
    "\n",
    "    except:\n",
    "        #連線資源error,Try reconnecting\n",
    "        time.sleep(20)\n",
    "        num=num-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def craw_(next_url):\n",
    "    \n",
    "   \n",
    "    time.sleep(1)\n",
    "    global num\n",
    "    \n",
    "    target_url='http://kmweb.coa.gov.tw'+next_url\n",
    "\n",
    "    try:\n",
    "        all_html=requests.get(target_url,headers = headers)    \n",
    "        soup1=BeautifulSoup(all_html.text,'lxml')\n",
    "        title=soup1.find('span',id='ctl00_ContentPlaceHolder1_QuestionText').h3.text\n",
    "        title=re.sub(\"標題：\",\"\",str(title))\n",
    "        contect=soup1.find('div',class_='problem').text\n",
    "        article_infor=soup1.find(class_='subright').find_all('li')\n",
    "\n",
    "        artDate=re.sub(\"發問日期：\",\"\",str(article_infor[1].text))\n",
    "        artBrow_num=re.sub(\"瀏覽數：\",\"\",str(article_infor[3].text))\n",
    "        artDisc_num=re.sub(\"討論數：\",\"\",str(article_infor[4].text))\n",
    "        artTrace_num=re.sub(\"追蹤數：\",\"\",str(article_infor[5].text))\n",
    "        artOpinion_num=re.sub(\"意見數：\",\"\",str(article_infor[6].text))\n",
    "        artEva_num=re.sub(\"平均評價：\\(\",\"\",str(article_infor[7].text))\n",
    "        artEva_num=re.sub(\"人評價\\)\",\"\",str(artEva_num))\n",
    "\n",
    "        reply_list=soup1.find_all(class_='DisList')\n",
    "        \n",
    "        reply=[]\n",
    "        #for each replier\n",
    "        for i in reply_list:\n",
    "\n",
    "            rep_content=i.find('p')#get reply content\n",
    "            rep_href= rep_content.find_all('a')\n",
    "            for j in  rep_href:\n",
    "                rep_content.a.extract()#delete all href in reply\n",
    "\n",
    "            replier_info=i.find_all('li')\n",
    "\n",
    "            rep_name=replier_info[0].text\n",
    "            rep_date=replier_info[1].text\n",
    "            rep_date=re.sub(\"發表於 \",\"\",str(rep_date))\n",
    "            rep_member=replier_info[0].nextSibling\n",
    "            rep_member=re.sub(\"\\(\",\"\",str(rep_member))\n",
    "            rep_member=re.sub(\"\\)\",\"\",str(rep_member))\n",
    "            reply.append({\n",
    "                'rep_content':rep_content.text,\n",
    "                'rep_name':rep_name,\n",
    "                'rep_member':rep_member,\n",
    "                'rep_date':rep_date\n",
    "\n",
    "            })\n",
    "\n",
    "\n",
    "        bag={\n",
    "#             'nId':num,\n",
    "#             'artTitle':title,\n",
    "            'artUrl':target_url,\n",
    "#             'artContent':contect,\n",
    "#             'artReply':reply,\n",
    "#             'artBrow_num':artBrow_num,\n",
    "#             'artDisc_num':artDisc_num,\n",
    "#             'artTrace_num':artTrace_num,\n",
    "#             'artOpinion_num':artOpinion_num,\n",
    "#             'artEva_num':artEva_num,\n",
    "#             'artDate':artDate,\n",
    "            'error':0\n",
    "        }\n",
    "        #抓取成功\n",
    "        print(str(num)+\".:\"+title)\n",
    "    except Exception as e:\n",
    "\n",
    "        bag={\n",
    "            'nId':num,\n",
    "            'artTitle':\"\",\n",
    "            'artUrl':target_url,\n",
    "\n",
    "            'artContent':\"\",\n",
    "            'artReply':\"\",             \n",
    "            'artBrow_num':\"\",\n",
    "            'artDisc_num':\"\",\n",
    "            'artTrace_num':\"\",\n",
    "            'artOpinion_num':\"\",\n",
    "            'artEva_num':\"\",\n",
    "            'artDate':\"\",\n",
    "            'error':1\n",
    "        }\n",
    "        #抓取失敗\n",
    "        print(e)\n",
    "        print(str(num)+\".:Error find!Connect again...\")\n",
    "        time.sleep(20)\n",
    "\n",
    "    finally:\n",
    "        ###連接MONGO\n",
    "\n",
    "\n",
    "        uri = \"\"\n",
    "        client = MongoClient(uri)\n",
    "\n",
    "        db = client.yuming\n",
    "        one_document = db.Knowledge_latest_agr\n",
    "        current_insert=one_document.find({'artUrl':target_url}).count()\n",
    "        if(current_insert==0):one_document.insert_one(bag)\n",
    "        if(current_insert>0):\n",
    "            print(\"已存在此文章\")\n",
    "            num=num-1\n",
    "        \n",
    "        if(target_url ==\"http://kmweb.coa.gov.tw/knowledge/knowledge_cp.aspx?ArticleId=89879&ArticleType=A&CategoryId=A&kpi=0&dateS=&dateE=\"):last_art=True\n",
    "#         try:\n",
    "#             next_url=soup1.find('span',id='ctl00_ContentPlaceHolder1_labNext').a['href']\n",
    "\n",
    "#         except:\n",
    "#             #連線資源error,Try reconnecting\n",
    "#             time.sleep(10)\n",
    "#             num=num-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uri = \"\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "db = client.yuming\n",
    "current_insert=one_document.find({'artUrl':target_url}).count()\n",
    "print(target_url)\n",
    "if(current_insert==0):\n",
    "    num=num-1\n",
    "    print(\"已存在此文章\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###連接MONGO\n",
    "\n",
    "\n",
    "uri = \"\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "db = client.yuming\n",
    "one_document = db.KnowledgeClass_Latest\n",
    "list=one_document.find({'error':0})\n",
    "for i in list:\n",
    "    print(i['artUrl'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
